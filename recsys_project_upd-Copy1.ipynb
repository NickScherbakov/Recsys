{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9daa20-4463-4c29-86d7-e8b55a836d6a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-11e06e57608fe1f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Проект по курсу \"Рекомендательные системы\"\n",
    "  \n",
    "Правила заполнения ноутбуков на авто-проверку:\n",
    "- повторить окружение преподавателя\n",
    "Python 3.13.0\n",
    "```bash\n",
    "pip install implicit==0.7.2 \"rectools[all]==0.17.0\" pandas==2.3.3 numpy==2.3.3 scipy==1.16.2  requests==2.32.5 catboost==1.2.8 scikit-learn==1.7.2\n",
    "```\n",
    "- все решение должно полностью помещаться в функцию solution(смотри пример). Если вы хотите реализовать дополнительные функции - поместите их в область видимости soluition. Нельзя использовать дополнительные файлы.\n",
    "- не добавлять новые импорты и не использовать дополнительные библиотеки. В противном случае ноутбук не пройдёт проверку и получит `0` баллов\n",
    "- не добавлять аргументов в solution\n",
    "- писать код только между # CODE BEGIN и # CODE END\n",
    "- не менять код преподавателя\n",
    "- не добавлять новые ячейки\n",
    "- следить, чтобы не было warning - они автоматом фейлят задание\n",
    "- перед сдачей проверить, что весь ноутбук прогоняется от начала до конца и все тесты проходят\n",
    "- data_path должен браться из переменной окружения как в коде ниже\n",
    "- Код должен выполняться за разумное время - ограничение 20 мин на 4 CPU и 16 Gb RAM без GPU. Не нужно ставить огромное количество эпох.\n",
    "- Постарайтесь максимально зафиксировать сиды, чтобы не было сюрпризов во время автоматической проверки. В случае, если решение выдает разное качество при разных запусках, то в зачет идет то значение, которое получилось при автоматической проверке.\n",
    "\n",
    "\n",
    "В данном проекте вам возможно захочется подбирать гипер-параметры моделей. Писать код для подбора гипер-параметров, использовать optuna и т.п. рекомендуем в отдельном ноутбуке.\n",
    "\n",
    "Библиотеки implicit и lightfm не фиксируют random state при num_threads > 1. Если результат работы модели не сильно превышает  необходимый порог и рандом может опустить его ниже требуемого уровня, рекомендуем продолжить повышение качества модели: тюнинг гипер-параметров, подбор фичей, подбор метода обработки датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c2daf",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661b22c",
   "metadata": {},
   "source": [
    "Вам предлагается реализовать рекомендательную систему для фильмов KION.\n",
    "Решение должно быть полностью упаковано в функцию solution. Качество будет проверяться с помощью метрики MAP@10 на отложенной неделе. Итоговый бал определеятся функцией scorer - вы можете посмотреть его сразу, но если модель не подразумевает фиксирование random state, то после прогона автоматической системой результат может немного отличаться.\n",
    "\n",
    "В качестве примера реализована базовая рекомендательная система на основе ease. Ваша задача - улучшить эту систему.\n",
    "\n",
    "Чтобы решение отрабатывало быстрее будем использовать 10% от общего числа пользователей.\n",
    "\n",
    "В случае, если в вашем решении будет найден Hardcode элементов тестового датафрейма - работа будет аннулирована.\n",
    "\n",
    "Напоминаю, что для зачета по курсу нужно набрать в сумме с доп баллами и первым дз 60 баллов.\n",
    "\n",
    "Успехов!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3166e",
   "metadata": {},
   "source": [
    "Подсказки:\n",
    "- Можно посмотреть документацию rectools\n",
    "- Можно поссмотреть ноутбуки с семинаров и предыдущую версию проекта\n",
    "- Не стесняйтесь добавлять фичи в ранжирование\n",
    "- Скорее всего вам понадобятся как отбор кандидатов, так и ранжирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49cde7-2156-468a-b3e2-e8467e241cf8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1891eaa3c13c8609",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Импорты и данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "724a1ce6-1a8d-4f7a-95df-17021d831dfc",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e865769efae1be6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.5\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b118efea-a833-402f-9048-562d79dcea42",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49e3b781726cecc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.2\n",
      "0.17.0\n",
      "2.3.3\n",
      "2.3.3\n",
      "1.16.2\n",
      "2.32.5\n",
      "1.2.8\n",
      "1.7.2\n"
     ]
    }
   ],
   "source": [
    "# Убедитесь, что вы не добавляете новые импорты в ноутбук. Решение должно быть ограничено данными библиотеками\n",
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import implicit\n",
    "import rectools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import requests\n",
    "import catboost\n",
    "import sklearn\n",
    "\n",
    "from rectools import models\n",
    "from rectools import dataset\n",
    "from rectools import metrics\n",
    "\n",
    "print(implicit.__version__)\n",
    "print(rectools.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(scipy.__version__)\n",
    "print(requests.__version__)\n",
    "print(catboost.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3591f25-aedf-42b5-8b65-1f02e51d3020",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ebdc35957207757",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<threadpoolctl.threadpool_limits at 0x71eac111d590>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "# For implicit ALS\n",
    "import threadpoolctl\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "threadpoolctl.threadpool_limits(1, \"blas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265ea46-e840-452d-b43b-343cbb7eb160",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42bc3babcb8ca15b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Если у вас нет данных, то используйте закомментированный код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f385743a-3642-4152-82bd-e4eca87130bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import zipfile as zf\n",
    "\n",
    "# url = 'https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip'\n",
    "\n",
    "# req = requests.get(url, stream=True)\n",
    "\n",
    "# with open('kion.zip', 'wb') as fd:\n",
    "#     total_size_in_bytes = int(req.headers.get('Content-Length', 0))\n",
    "#     progress_bar = tqdm(desc='kion dataset download', total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "#     for chunk in req.iter_content(chunk_size=2 ** 20):\n",
    "#         progress_bar.update(len(chunk))\n",
    "#         fd.write(chunk)\n",
    "#\n",
    "# files = zf.ZipFile('kion.zip', 'r')\n",
    "# files.extractall()\n",
    "# files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b128d75-5970-42c0-b89e-1d48c1688936",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.environ.get(\"DATA_PATH\")\n",
    "if data_path is None:\n",
    "    data_path = \"data_original\"  # ваш путь к данным до папки data_original включительно (поменяйте при необходимости)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e1b9888-cdc7-47a3-9162-a1ae7de7144e",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1b82be4e2c39f91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weight</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>791466</td>\n",
       "      <td>8199</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>713</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>988709</td>\n",
       "      <td>7571</td>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>6558</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>927973</td>\n",
       "      <td>9617</td>\n",
       "      <td>2021-06-19</td>\n",
       "      <td>8422</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>505244</td>\n",
       "      <td>15297</td>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>15991</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>81786</td>\n",
       "      <td>2616</td>\n",
       "      <td>2021-07-24</td>\n",
       "      <td>41422</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id   datetime  weight  watched_pct\n",
       "10   791466     8199 2021-07-27     713          9.0\n",
       "11   988709     7571 2021-07-07    6558        100.0\n",
       "18   927973     9617 2021-06-19    8422        100.0\n",
       "22   505244    15297 2021-08-15   15991         63.0\n",
       "28    81786     2616 2021-07-24   41422         90.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(os.path.join(data_path, \"users.csv\"))\n",
    "items = pd.read_csv(os.path.join(data_path, \"items.csv\"))\n",
    "\n",
    "users = users.sample(frac=0.1, random_state=42)\n",
    "\n",
    "interactions = (\n",
    "    pd.read_csv(os.path.join(data_path, \"interactions.csv\"), parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={'total_dur': rectools.Columns.Weight,\n",
    "                     'last_watch_dt': rectools.Columns.Datetime})\n",
    ")\n",
    "\n",
    "\n",
    "interactions = interactions[interactions[\"user_id\"].isin(users[\"user_id\"])]\n",
    "\n",
    "\n",
    "print(interactions.shape)\n",
    "interactions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecfa3e3e-477e-449c-863f-83decd2a608f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-457223d68ac460f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24771\n",
      "9099\n"
     ]
    }
   ],
   "source": [
    "N_DAYS = 7\n",
    "\n",
    "max_date = interactions['datetime'].max()\n",
    "train = interactions[(interactions['datetime'] <= max_date - pd.Timedelta(days=N_DAYS))]\n",
    "test = interactions[(interactions['datetime'] > max_date - pd.Timedelta(days=N_DAYS))]\n",
    "\n",
    "catalog = train[rectools.Columns.Item].unique()\n",
    "\n",
    "test_users = test[rectools.Columns.User].unique()\n",
    "cold_users = set(test_users) - set(train[rectools.Columns.User])\n",
    "test.drop(test[test[rectools.Columns.User].isin(cold_users)].index, inplace=True)\n",
    "hot_users = test[rectools.Columns.User].unique()\n",
    "print(test.shape[0])\n",
    "print(test[rectools.Columns.User].nunique())\n",
    "\n",
    "def scorer(map: float):\n",
    "    print(f\"Ваш MAP: {map}\")\n",
    "    UPPER_BOUND = 0.089\n",
    "    LOWER_BOUND = 0.071\n",
    "    score = int(min(max( (map - LOWER_BOUND) / (UPPER_BOUND - LOWER_BOUND), 0), 1) * 80)\n",
    "    print(f\"Ваш итоговый балл: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d2619d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(train: pd.DataFrame, users: pd.DataFrame, items: pd.DataFrame):\n",
    "    # CODE BEGIN\n",
    "    # Импорты внутри функции (как требуется)\n",
    "    import rectools\n",
    "    from rectools import models, dataset\n",
    "    import numpy as np\n",
    "\n",
    "    # Фиксация random state\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # 1. ПРЕПРОЦЕССИНГ ДАННЫХ\n",
    "    # Взвешивание взаимодействий на основе watched_pct\n",
    "    train_processed = train.copy()\n",
    "\n",
    "    # Создаем веса: комбинация просмотренного процента и длительности\n",
    "    # Более высокий вес для полностью просмотренных фильмов\n",
    "    train_processed[rectools.Columns.Weight] = np.where(\n",
    "        train_processed['watched_pct'] >= 80,\n",
    "        train_processed['weight'] * 3.0,  # Высокий вес для досмотренных\n",
    "        np.where(\n",
    "            train_processed['watched_pct'] >= 50,\n",
    "            train_processed['weight'] * 2.0,  # Средний вес\n",
    "            train_processed['weight'] * 0.5   # Низкий вес для недосмотренных\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Определяем пользователей для рекомендаций (hot users)\n",
    "    hot_users = train_processed[rectools.Columns.User].unique()\n",
    "\n",
    "    # 2. СОЗДАНИЕ ДАТАСЕТА через rectools\n",
    "    dataset_train = rectools.dataset.Dataset.construct(train_processed)\n",
    "\n",
    "    # 3. ОБУЧЕНИЕ НЕСКОЛЬКИХ МОДЕЛЕЙ (Ensemble подход)\n",
    "\n",
    "    # Модель 1: EASE (быстрая и эффективная)\n",
    "    ease_model = rectools.models.EASEModel(regularization=500)\n",
    "    ease_model.fit(dataset_train)\n",
    "\n",
    "    # Модель 2: ALS через rectools\n",
    "    als_model = rectools.models.ImplicitALSWrapperModel(\n",
    "        factors=128,\n",
    "        regularization=0.01,\n",
    "        iterations=20,\n",
    "        random_state=42,\n",
    "        num_threads=1\n",
    "    )\n",
    "    als_model.fit(dataset_train)\n",
    "\n",
    "    # Модель 3: Popular (для холодных пользователей и разнообразия)\n",
    "    popular_model = rectools.models.PopularModel()\n",
    "    popular_model.fit(dataset_train)\n",
    "\n",
    "    # 4. ГЕНЕРАЦИЯ КАНДИДАТОВ от разных моделей\n",
    "    k_candidates = 50  # Больше кандидатов для лучшего покрытия\n",
    "\n",
    "    # Получаем рекомендации от каждой модели\n",
    "    ease_recs = ease_model.recommend(\n",
    "        users=hot_users,\n",
    "        dataset=dataset_train,\n",
    "        k=k_candidates,\n",
    "        filter_viewed=True\n",
    "    )\n",
    "\n",
    "    als_recs = als_model.recommend(\n",
    "        users=hot_users,\n",
    "        dataset=dataset_train,\n",
    "        k=k_candidates,\n",
    "        filter_viewed=True\n",
    "    )\n",
    "\n",
    "    popular_recs = popular_model.recommend(\n",
    "        users=hot_users,\n",
    "        dataset=dataset_train,\n",
    "        k=k_candidates,\n",
    "        filter_viewed=True\n",
    "    )\n",
    "\n",
    "    # 5. ОБЪЕДИНЕНИЕ И РАНЖИРОВАНИЕ КАНДИДАТОВ\n",
    "    # Присваиваем веса каждой модели на основе позиции в рекомендациях\n",
    "    ease_recs['ease_score'] = 1.0 / (ease_recs['rank'] + 1)\n",
    "    als_recs['als_score'] = 1.0 / (als_recs['rank'] + 1)\n",
    "    popular_recs['popular_score'] = 1.0 / (popular_recs['rank'] + 1)\n",
    "\n",
    "    # Объединяем все рекомендации\n",
    "    all_recs = pd.concat([\n",
    "        ease_recs[['user_id', 'item_id', 'ease_score']],\n",
    "        als_recs[['user_id', 'item_id', 'als_score']],\n",
    "        popular_recs[['user_id', 'item_id', 'popular_score']]\n",
    "    ], axis=0)\n",
    "\n",
    "    # Группируем по (user_id, item_id) и суммируем скоры\n",
    "    combined = all_recs.groupby(['user_id', 'item_id']).agg({\n",
    "        'ease_score': 'sum',\n",
    "        'als_score': 'sum', \n",
    "        'popular_score': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Заполняем пропуски нулями\n",
    "    combined = combined.fillna(0)\n",
    "\n",
    "    # 6. ВЫЧИСЛЕНИЕ ФИНАЛЬНОГО СКОРА с весами моделей\n",
    "    # EASE обычно лучше работает, даем ему больший вес\n",
    "    combined['final_score'] = (\n",
    "        combined['ease_score'] * 0.5 +      # EASE - основная модель\n",
    "        combined['als_score'] * 0.35 +       # ALS - вторая по важности\n",
    "        combined['popular_score'] * 0.15     # Popular - для разнообразия\n",
    "    )\n",
    "\n",
    "    # 7. ДОПОЛНИТЕЛЬНЫЕ УЛУЧШЕНИЯ\n",
    "    # Добавим бустинг для популярных айтемов среди активных пользователей\n",
    "    item_popularity = train_processed.groupby(rectools.Columns.Item).agg({\n",
    "        rectools.Columns.User: 'count',\n",
    "        'watched_pct': 'mean'\n",
    "    }).reset_index()\n",
    "    item_popularity.columns = ['item_id', 'user_count', 'avg_watched_pct']\n",
    "\n",
    "    # Нормализуем популярность\n",
    "    item_popularity['popularity_boost'] = (\n",
    "        (item_popularity['user_count'] / item_popularity['user_count'].max()) * 0.3 +\n",
    "        (item_popularity['avg_watched_pct'] / 100.0) * 0.2\n",
    "    )\n",
    "\n",
    "    # Объединяем с рекомендациями\n",
    "    combined = combined.merge(\n",
    "        item_popularity[['item_id', 'popularity_boost']], \n",
    "        on='item_id', \n",
    "        how='left'\n",
    "    )\n",
    "    combined['popularity_boost'] = combined['popularity_boost'].fillna(0)\n",
    "\n",
    "    # Применяем бустинг\n",
    "    combined['final_score'] = combined['final_score'] + combined['popularity_boost']\n",
    "\n",
    "    # 8. ФОРМИРОВАНИЕ ФИНАЛЬНЫХ РЕКОМЕНДАЦИЙ ТОП-10\n",
    "    final_recommendations = []\n",
    "\n",
    "    for user_id in hot_users:\n",
    "        user_recs = combined[combined['user_id'] == user_id].copy()\n",
    "\n",
    "        # Сортируем по финальному скору\n",
    "        user_recs = user_recs.sort_values('final_score', ascending=False)\n",
    "\n",
    "        # Берем топ-10\n",
    "        top_10 = user_recs.head(10).copy()\n",
    "\n",
    "        # Если меньше 10 рекомендаций, дополняем популярными\n",
    "        if len(top_10) < 10:\n",
    "            # Получаем уже рекомендованные айтемы\n",
    "            recommended_items = set(top_10['item_id'].values)\n",
    "\n",
    "            # Берем топ популярных, которых нет в рекомендациях\n",
    "            popular_items = item_popularity.sort_values('popularity_boost', ascending=False)\n",
    "            additional_items = popular_items[\n",
    "                ~popular_items['item_id'].isin(recommended_items)\n",
    "            ]['item_id'].head(10 - len(top_10)).values\n",
    "\n",
    "            # Добавляем недостающие\n",
    "            for item_id in additional_items:\n",
    "                top_10 = pd.concat([\n",
    "                    top_10,\n",
    "                    pd.DataFrame([{\n",
    "                        'user_id': user_id,\n",
    "                        'item_id': item_id,\n",
    "                        'final_score': 0.0\n",
    "                    }])\n",
    "                ], ignore_index=True)\n",
    "\n",
    "        # Убеждаемся, что берем ровно 10\n",
    "        top_10 = top_10.head(10)\n",
    "\n",
    "        # Добавляем ранг (0-9)\n",
    "        top_10['rank'] = range(len(top_10))\n",
    "\n",
    "        final_recommendations.append(top_10[['user_id', 'item_id', 'rank']])\n",
    "\n",
    "    # Объединяем все рекомендации\n",
    "    result = pd.concat(final_recommendations, ignore_index=True)\n",
    "\n",
    "    # 9. ФИНАЛЬНАЯ ПРОВЕРКА И ФОРМАТИРОВАНИЕ\n",
    "    # Убеждаемся, что типы данных правильные\n",
    "    result['user_id'] = result['user_id'].astype(train[rectools.Columns.User].dtype)\n",
    "    result['item_id'] = result['item_id'].astype(train[rectools.Columns.Item].dtype)\n",
    "    result['rank'] = result['rank'].astype(int)\n",
    "\n",
    "    # Проверка: каждый пользователь должен иметь ровно 10 рекомендаций\n",
    "    recs_per_user = result.groupby('user_id').size()\n",
    "    assert all(recs_per_user == 10), \"Не все пользователи имеют 10 рекомендаций\"\n",
    "\n",
    "    # CODE END\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e5101e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 1.37 s, total: 31.5 s\n",
      "Wall time: 31.5 s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ImplicitALSWrapperModel.__init__() got an unexpected keyword argument 'factors'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mrecos = solution(train.copy(), users.copy(), items.copy())\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mscorer(rectools.metrics.MAP(10).calc(recos, test))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/recsys_env/lib/python3.13/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/recsys_env/lib/python3.13/site-packages/IPython/core/magics/execution.py:1452\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1451\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1452\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1454\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/recsys_env/lib/python3.13/site-packages/IPython/core/magics/execution.py:1416\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1414\u001b[39m st = clock2()\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1417\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1418\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36msolution\u001b[39m\u001b[34m(train, users, items)\u001b[39m\n\u001b[32m     37\u001b[39m ease_model.fit(dataset_train)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Модель 2: ALS через rectools\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m als_model = \u001b[43mrectools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImplicitALSWrapperModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfactors\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     46\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m als_model.fit(dataset_train)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Модель 3: Popular (для холодных пользователей и разнообразия)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: ImplicitALSWrapperModel.__init__() got an unexpected keyword argument 'factors'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recos = solution(train.copy(), users.copy(), items.copy())\n",
    "scorer(rectools.metrics.MAP(10).calc(recos, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f950f2b-fd70-425d-b7a8-84220ef5579f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "recsys_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
